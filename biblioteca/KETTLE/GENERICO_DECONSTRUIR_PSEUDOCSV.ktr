<?xml version="1.0" encoding="UTF-8"?>
<transformation>
  <info>
    <name>GENERICO_DECONSTRUIR_PSEUDOCSV</name>
    <description/>
    <extended_description/>
    <trans_version/>
    <trans_type>Normal</trans_type>
    <trans_status>0</trans_status>
    <directory>/</directory>
    <parameters>
      <parameter>
        <name>CAMPOS</name>
        <default_value>default</default_value>
        <description>Variable conteniendo los nombres de los campos necesarios para construir los registros. Se separa con lo indicado en enlosure y separador</description>
      </parameter>
      <parameter>
        <name>ENCLOSURE</name>
        <default_value>default</default_value>
        <description>String que se indica al inicio y al final de los valores</description>
      </parameter>
      <parameter>
        <name>SEPARADOR</name>
        <default_value>default</default_value>
        <description>String que separa los valores de una fila de otros</description>
      </parameter>
    </parameters>
    <log>
      <trans-log-table>
        <connection/>
        <schema/>
        <table/>
        <size_limit_lines/>
        <interval/>
        <timeout_days/>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STATUS</id>
          <enabled>Y</enabled>
          <name>STATUS</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
          <subject/>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
          <subject/>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
          <subject/>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
          <subject/>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
          <subject/>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
          <subject/>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>STARTDATE</id>
          <enabled>Y</enabled>
          <name>STARTDATE</name>
        </field>
        <field>
          <id>ENDDATE</id>
          <enabled>Y</enabled>
          <name>ENDDATE</name>
        </field>
        <field>
          <id>LOGDATE</id>
          <enabled>Y</enabled>
          <name>LOGDATE</name>
        </field>
        <field>
          <id>DEPDATE</id>
          <enabled>Y</enabled>
          <name>DEPDATE</name>
        </field>
        <field>
          <id>REPLAYDATE</id>
          <enabled>Y</enabled>
          <name>REPLAYDATE</name>
        </field>
        <field>
          <id>LOG_FIELD</id>
          <enabled>Y</enabled>
          <name>LOG_FIELD</name>
        </field>
        <field>
          <id>EXECUTING_SERVER</id>
          <enabled>N</enabled>
          <name>EXECUTING_SERVER</name>
        </field>
        <field>
          <id>EXECUTING_USER</id>
          <enabled>N</enabled>
          <name>EXECUTING_USER</name>
        </field>
        <field>
          <id>CLIENT</id>
          <enabled>N</enabled>
          <name>CLIENT</name>
        </field>
      </trans-log-table>
      <perf-log-table>
        <connection/>
        <schema/>
        <table/>
        <interval/>
        <timeout_days/>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>SEQ_NR</id>
          <enabled>Y</enabled>
          <name>SEQ_NR</name>
        </field>
        <field>
          <id>LOGDATE</id>
          <enabled>Y</enabled>
          <name>LOGDATE</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STEPNAME</id>
          <enabled>Y</enabled>
          <name>STEPNAME</name>
        </field>
        <field>
          <id>STEP_COPY</id>
          <enabled>Y</enabled>
          <name>STEP_COPY</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>INPUT_BUFFER_ROWS</id>
          <enabled>Y</enabled>
          <name>INPUT_BUFFER_ROWS</name>
        </field>
        <field>
          <id>OUTPUT_BUFFER_ROWS</id>
          <enabled>Y</enabled>
          <name>OUTPUT_BUFFER_ROWS</name>
        </field>
      </perf-log-table>
      <channel-log-table>
        <connection/>
        <schema/>
        <table/>
        <timeout_days/>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>LOGGING_OBJECT_TYPE</id>
          <enabled>Y</enabled>
          <name>LOGGING_OBJECT_TYPE</name>
        </field>
        <field>
          <id>OBJECT_NAME</id>
          <enabled>Y</enabled>
          <name>OBJECT_NAME</name>
        </field>
        <field>
          <id>OBJECT_COPY</id>
          <enabled>Y</enabled>
          <name>OBJECT_COPY</name>
        </field>
        <field>
          <id>REPOSITORY_DIRECTORY</id>
          <enabled>Y</enabled>
          <name>REPOSITORY_DIRECTORY</name>
        </field>
        <field>
          <id>FILENAME</id>
          <enabled>Y</enabled>
          <name>FILENAME</name>
        </field>
        <field>
          <id>OBJECT_ID</id>
          <enabled>Y</enabled>
          <name>OBJECT_ID</name>
        </field>
        <field>
          <id>OBJECT_REVISION</id>
          <enabled>Y</enabled>
          <name>OBJECT_REVISION</name>
        </field>
        <field>
          <id>PARENT_CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>PARENT_CHANNEL_ID</name>
        </field>
        <field>
          <id>ROOT_CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>ROOT_CHANNEL_ID</name>
        </field>
      </channel-log-table>
      <step-log-table>
        <connection/>
        <schema/>
        <table/>
        <timeout_days/>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STEPNAME</id>
          <enabled>Y</enabled>
          <name>STEPNAME</name>
        </field>
        <field>
          <id>STEP_COPY</id>
          <enabled>Y</enabled>
          <name>STEP_COPY</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>LOG_FIELD</id>
          <enabled>N</enabled>
          <name>LOG_FIELD</name>
        </field>
      </step-log-table>
      <metrics-log-table>
        <connection/>
        <schema/>
        <table/>
        <timeout_days/>
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>METRICS_DATE</id>
          <enabled>Y</enabled>
          <name>METRICS_DATE</name>
        </field>
        <field>
          <id>METRICS_CODE</id>
          <enabled>Y</enabled>
          <name>METRICS_CODE</name>
        </field>
        <field>
          <id>METRICS_DESCRIPTION</id>
          <enabled>Y</enabled>
          <name>METRICS_DESCRIPTION</name>
        </field>
        <field>
          <id>METRICS_SUBJECT</id>
          <enabled>Y</enabled>
          <name>METRICS_SUBJECT</name>
        </field>
        <field>
          <id>METRICS_TYPE</id>
          <enabled>Y</enabled>
          <name>METRICS_TYPE</name>
        </field>
        <field>
          <id>METRICS_VALUE</id>
          <enabled>Y</enabled>
          <name>METRICS_VALUE</name>
        </field>
      </metrics-log-table>
    </log>
    <maxdate>
      <connection/>
      <table/>
      <field/>
      <offset>0.0</offset>
      <maxdiff>0.0</maxdiff>
    </maxdate>
    <size_rowset>100</size_rowset>
    <sleep_time_empty>50</sleep_time_empty>
    <sleep_time_full>50</sleep_time_full>
    <unique_connections>N</unique_connections>
    <feedback_shown>Y</feedback_shown>
    <feedback_size>500</feedback_size>
    <using_thread_priorities>Y</using_thread_priorities>
    <shared_objects_file/>
    <capture_step_performance>N</capture_step_performance>
    <step_performance_capturing_delay>1000</step_performance_capturing_delay>
    <step_performance_capturing_size_limit>100</step_performance_capturing_size_limit>
    <dependencies>
    </dependencies>
    <partitionschemas>
    </partitionschemas>
    <slaveservers>
    </slaveservers>
    <clusterschemas>
    </clusterschemas>
    <created_user>-</created_user>
    <created_date>2024/01/22 13:41:43.545</created_date>
    <modified_user>-</modified_user>
    <modified_date>2024/01/22 13:41:43.545</modified_date>
    <key_for_session_key>H4sIAAAAAAAAAAMAAAAAAAAAAAA=</key_for_session_key>
    <is_key_private>N</is_key_private>
  </info>
  <notepads>
  </notepads>
  <order>
    <hop>
      <from>Inicializa</from>
      <to>Deconstruir Pseudo CSV</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Deconstruir Pseudo CSV</from>
      <to>Copia filas a resultado</to>
      <enabled>Y</enabled>
    </hop>
  </order>
  <step>
    <name>Copia filas a resultado</name>
    <type>RowsToResult</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name/>
    </partitioning>
    <attributes/>
    <cluster_schema/>
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>624</xloc>
      <yloc>192</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Deconstruir Pseudo CSV</name>
    <type>ScriptValueMod</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name/>
    </partitioning>
    <compatible>N</compatible>
    <optimizationLevel>9</optimizationLevel>
    <jsScripts>
      <jsScript>
        <jsScript_type>0</jsScript_type>
        <jsScript_name>Script 1</jsScript_name>
        <jsScript_script>trans_Status = CONTINUE_TRANSFORMATION; //Estado default (Permite arrojar error por el javascript)

if ( !procesaFila() ) 
	trans_Status = ERROR_TRANSFORMATION;
else
	trans_Status = SKIP_TRANSFORMATION;
</jsScript_script>
      </jsScript>
      <jsScript>
        <jsScript_type>1</jsScript_type>
        <jsScript_name>Item_0</jsScript_name>
        <jsScript_script>function procesaFila() 
{
	_step_.logBasic("***Generico Decostruir Pseudo CSV para Operaciones TOPAZ***");
	_step_.logBasic("***Inicia Deconstruccion de Pseudo CSV***");

    // Obtiene el parámetro ENCLOSURE
    var enclosure = String(getVariable("ENCLOSURE", ""));

    if (enclosure == "default") 
	{
		abortar("No se recibió el parámetro ENCLOSURE");
        return false;
    }
	else
	{
		_step_.logBasic("***Generico Decostruir Pseudo CSV para Operaciones TOPAZ***");
		_step_.logBasic("Valor Parametro ENCLOSURE: " + enclosure);
	}

    // Obtiene el parámetro SEPARADOR
    var separador = String(getVariable("SEPARADOR", ""));

    if (separador == "default") 
	{
		abortar("No se recibió el parámetro SEPARADOR");
        return false;
    }
	else
	{
		_step_.logBasic("***Generico Decostruir Pseudo CSV para Operaciones TOPAZ***");
		_step_.logBasic("Valor Parametro SEPARADOR: " + separador);
	}

    // Obtiene el parámetro CAMPOS
    var parametroCampos = String(getVariable("CAMPOS", ""));

    if (parametroCampos == "default") 
	{
		abortar("No se recibió el parámetro CAMPOS");
        return false;
    }
	else
	{
		_step_.logBasic("***Generico Decostruir Pseudo CSV para Operaciones TOPAZ***");
		_step_.logBasic("Valor Parametro CAMPOS: " + parametroCampos);
	}

    // Parsea el parámetro CAMPOS
	_step_.logBasic("***Generico Decostruir Pseudo CSV para Operaciones TOPAZ***");
	_step_.logBasic("***Obteniendo Columnas de parametro CAMPOS***");

    var camposContenido = parsearCSV(parametroCampos, enclosure, separador);

    if (camposContenido == null) 
	{
		abortar("No se pudo parsear el parámetro CAMPOS. Revise el valor de los Parametros enviados.");
        return false;
    }

    // Arreglo conteniendo por cada elemento, un arreglo con todos los valores
    // parseados
    var campoValores = [];
    
    // Variable conteniendo la cantidad de registros. Se inicializa en -1 para
    // poder cargarla con la cantidad de valores que reciba en el primer campo
    var cantidadRegistros = -1;

    // Recorre el parametro de camposContenido y por cada campo carga los valores
	_step_.logBasic("***Generico Decostruir Pseudo CSV para Operaciones TOPAZ***");
	_step_.logBasic("***Obteniendo valores de Filas por cada columna***");

    for (var i = 0; i &lt; camposContenido.length; i++) 
	{
        var campo = String(camposContenido[i]);

        // Agrega campo con el nombre recibido a la metadata de la fila de salida
        getOutputRowMeta().addValueMeta(new org.pentaho.di.core.row.ValueMeta(campo, org.pentaho.di.core.row.ValueMetaInterface.TYPE_STRING, org.pentaho.di.core.row.ValueMetaInterface.STORAGE_TYPE_NORMAL));

        // Obtiene el parámetro con el nombre del campo informado en el parámetro CAMPO
        var parametroValores = getVariable(campo, "default");
		_step_.logBasic("***Generico Decostruir Pseudo CSV para Operaciones TOPAZ***");
		_step_.logBasic("Valor del campo: " + campo + " = " + parametroValores);


        if (parametroValores == "default") 
		{
			abortar("No se encontró el campo " + campo + " en los parametros inyectados, sin embargo el mismo se indica en el parametro CAMPOS");
            return false;
        }

        var valores = parsearCSV(parametroValores, enclosure, separador);

        if (valores == null) 
		{
			abortar("No se pudo parsear el campo " + campo);
            return false;
        }

        // Si no esta setteada la cantidad de registros, la inicializa con la cantidad que tenga la fila.
        if (cantidadRegistros == -1) 
		{
            cantidadRegistros = valores.length;
        }
		// Si esta setteada y es distinta a la cantidad que tiene este campo, aborta.
		else if (cantidadRegistros != valores.length) 
		{
			abortar("Se encontraron inconsistencias en la cantidad de filas informadas por cada campo. Cada variable array debe tener la misma cantidad de elementos.");
            return false;
        }

        campoValores[i] = valores;

    }

    // Crea una copia de la fila de entrada para construir la fila de salida
    // 
    // PD: Que raro que es javascript
    var outputRowData = row.slice();

	_step_.logBasic("***Generico Decostruir Pseudo CSV para Operaciones TOPAZ***");
	_step_.logBasic("***Generando Filas***");
    // Se lee los valores de manera horizontal, es decir una vez por campo, y se
    // construye la fila de salida.
    for (var i = 0; i &lt; campoValores[0].length; i++) 
	{

        for (var j = 0; j &lt; campoValores.length; j++) 
		{
            outputRowData[ getOutputRowMeta().indexOfValue( String(camposContenido[j] ) ) ] = campoValores[j][i];
        }

        // Agrega la fila al resultado
        putRow( outputRowData);
    }

    return true;

}

// @contenido = Campo conteniendo los valores separados por delimitador para la columna
// @enclosure = Marca que indica el inicio y el cierre de un valor
// @separador = Marca que indica la separación de valores
function parsearCSV(contenido, enclosure, separador) 
{

	contenido = String(contenido);
    enclosure = String(enclosure);
    separador = String(separador);

    var cadenaAbierta = false;
    
	var output = [];

	var separado = contenido.split(separador);

    for (var i = 0; i &lt; separado.length; i++) {

        var cadena = String(separado[i]);

		if ( trim(cadena) == "") continue;

		// Debe iniciar con enclosure
		if ( !startsWith(cadena, enclosure) ) {
			return null;
		}

        // Bandera que determina si la cadena generada tiene enclosure al final
        var estaCerrado = endsWith( cadena, enclosure );
        
        // Mientras no encuentre un enclosure al final, concatena los elementos.
		while ( !estaCerrado ) {

            if ( separado.length &lt;= i + 1 )
				return null;
            else
                cadena += ';' + separado[++i];

            if ( endsWith( cadena, enclosure ) )
                estaCerrado = true;
            
        }

        output.push(cadena.substring(1, cadena.length - 1));
    }
    return output;
}

// @cadena = String sobre el cual se quiere saber si inicia con la comparacion
// @comparacion = String a encontrar en el inicio de la cadena
function startsWith(cadena, comparacion) 
{
	if (comparacion.length > cadena.length)
		return false;
	
	return cadena.substring(0, comparacion.length) == comparacion;

}

// @cadena = String sobre el cual se quiere saber si finaliza con la comparacion
// @comparacion = String a encontrar en el final de la cadena
function endsWith (cadena, comparacion) 
{
	if (comparacion.length > cadena.length)
		return false;
	
	return cadena.substring(cadena.length - comparacion.length, cadena.length) == comparacion;

}

//Funcion que setea variables de error y aborta
function abortar (MSG)
{
	writeToLog("e", "***Generico Decostruir Pseudo CSV para Operaciones TOPAZ***");
	writeToLog("e", "Error: " + MSG);
	setVariable("RESULTADO", MSG, "r");
}
</jsScript_script>
      </jsScript>
    </jsScripts>
    <fields>    </fields>
    <attributes/>
    <cluster_schema/>
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>400</xloc>
      <yloc>192</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Inicializa</name>
    <type>DataGrid</type>
    <description/>
    <distribute>Y</distribute>
    <custom_distribution/>
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name/>
    </partitioning>
    <fields>
    </fields>
    <data>
      <line>  </line>
    </data>
    <attributes/>
    <cluster_schema/>
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>192</xloc>
      <yloc>192</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step_error_handling>
  </step_error_handling>
  <slave-step-copy-partition-distribution>
  </slave-step-copy-partition-distribution>
  <slave_transformation>N</slave_transformation>
  <attributes/>
</transformation>
